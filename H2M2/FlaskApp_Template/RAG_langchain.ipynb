{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanneliu/Desktop/AI4DM/H2M1/FlaskApp_Template/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/joanneliu/Desktop/AI4DM/H2M1/FlaskApp_Template/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/dair-ai/emotion/unsplit/train-00000-of-00001.parquet\")\n",
    "df.head(10)\n",
    "df = df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_emotions_to_txt(df, output_file):\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Group the dataframe by 'label' (emotion types)\n",
    "        grouped = df.groupby('label')\n",
    "        emotion_type=None\n",
    "        \n",
    "        # Loop through each story type and its corresponding stories\n",
    "        for emotion_type_id, emotions in grouped:\n",
    "            # Write the story type as a heading\n",
    "            if emotion_type_id==0:\n",
    "                emotion_type=\"sadness\"\n",
    "            if emotion_type_id==1:\n",
    "                emotion_type=\"joy\"\n",
    "            if emotion_type_id==2:\n",
    "                emotion_type=\"love\"\n",
    "            if emotion_type_id==3:\n",
    "                emotion_type=\"anger\"\n",
    "            if emotion_type_id==4:\n",
    "                emotion_type=\"fear\"\n",
    "            if emotion_type_id==5:\n",
    "                emotion_type=\"surprise\"\n",
    "            f.write(f\"{emotion_type}\\n\")\n",
    "            \n",
    "            # Loop through all stories under this story type and write them\n",
    "            for emotion in emotions['text']:\n",
    "                f.write(f\"{emotion}\\n\")  # Add a new line after each story\n",
    "            \n",
    "            # Add a couple of blank lines between different story types\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "    print(f\"Emotions have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions have been written to emotions.txt\n"
     ]
    }
   ],
   "source": [
    "write_emotions_to_txt(df, \"emotions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader #load the document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #for creating chunks from the loaded document\n",
    "from langchain_openai import OpenAIEmbeddings #for converting chunks into embeddings\n",
    "from langchain_chroma import Chroma #database for stroring the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joanneliu/Desktop/AI4DM/H2M1/FlaskApp_Template/chroma_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = os.getcwd()\n",
    "db_dir = os.path.join(dir,\"chroma_db\")\n",
    "print(db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text content from the .txt file and load it as langchain document\n",
    "loader = TextLoader('emotions.txt')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document chunk info:\n",
      "\n",
      "Number of document chunks: 5163\n",
      "Sample chunk: \n",
      "i feel she is emotionally disturbed and like she said its either me or her\n",
      "\n",
      "i just feel like i abused the time with the awesomeness that is my photo instructor\n",
      "\n",
      "i will be off to work again leaving the kids at home my feeling of discontent is replaced with happiness for having this\n",
      "\n",
      "i will feel weepy or anxious but it s manageable\n",
      "\n",
      "i feel totally rejected boo hoo never mind\n",
      "\n",
      "i am left feeling empty and confused\n",
      "\n",
      "i feel unloved right now\n",
      "\n",
      "i feel sort of lethargic\n",
      "\n",
      "i feel like i m constantly apologizing for lame food pictures so here i go again\n",
      "\n",
      "i get ready for bed that evening i am feeling really really discouraged and vow to do nothing but work on my cv the next day leave this silly writing behind buckle down and find real work\n",
      "\n",
      "i cant help feeling totally rejected like im the only one no one cares enough to ask\n",
      "\n",
      "i have been feeling very deprived\n",
      "\n",
      "ive just been feeling ignored\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the document into chunks using text splitters \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(document)\n",
    "\n",
    "print(\"Document chunk info:\\n\")\n",
    "print(f\"Number of document chunks: {len(chunks)}\")\n",
    "print(f\"Sample chunk: \\n{chunks[3].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embeddings using openAI embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x3aa5d3970>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the embeddings and chunks into Chroma DB\n",
    "Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the DB for retrieval\n",
    "embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorDB = Chroma(persist_directory=db_dir,embedding_function=embeddings_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up Retriver\n",
    "retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRetriever(dir):\n",
    "    \"\"\"\n",
    "    dir is the directory of the vector DB\n",
    "    \"\"\"\n",
    "    embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorDB = Chroma(persist_directory=dir,embedding_function=embeddings_used)\n",
    "    retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poemGeneration_langChain_RAG(msg,theme,retrieverDir):\n",
    "    \"\"\"\n",
    "    msg is the scenario for the story from the pic (hugging face model output);\n",
    "    type is the genre of the story- Horror, Fantasy, Adventure, Comedy, Mystery, Romance\n",
    "    retriever is the vector DB with relevant stories from txt version of \n",
    "        stories dataset from Hugging face - https://huggingface.co/datasets/ShehryarAzhar/stories\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "            timeout=None,\n",
    "            max_retries=2\n",
    "        )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a expert poem writer about the theme of {theme}\" \n",
    "        \"Use the following pieces of retrieved context to generate a poem based on the given emotion and around the theme of {theme} \"\n",
    "        \"keep the poem to less than 20 words.\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{scenario_lang}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    retriever = getRetriever(retrieverDir)\n",
    "\n",
    "    out_message = rag_chain.invoke({\n",
    "            \"theme\" : theme,\n",
    "            \"context\":retriever,\n",
    "            \"scenario_lang\" : msg,\n",
    "        })\n",
    "    \n",
    "    return out_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By the hearth's glow,  \n",
      "Memories softly burn,  \n",
      "In the heart's corner,  \n",
      "The fire's warmth returns.\n"
     ]
    }
   ],
   "source": [
    "emotion = \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\" #example output from huggingface model\n",
    "story = poemGeneration_langChain_RAG(\"warm\", emotion, db_dir)\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
