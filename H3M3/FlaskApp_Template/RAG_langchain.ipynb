{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/qwedsacf/story-generation/data/train-00000-of-00001-03560cf8eb66eee4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanneliu/Desktop/AI4DM/H3M3/FlaskApp_Template/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/joanneliu/Desktop/AI4DM/H3M3/FlaskApp_Template/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/juancopi81/orca-math-word-problems-140028_150030/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/bunnycore/Kind-Teacher/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stories_to_txt(df, output_file):\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write each text entry on a new line\n",
    "        for text in df['completion']:\n",
    "            f.write(f\"{text}\\n\")\n",
    "\n",
    "    print(f\"Problems have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problems have been written to context.txt\n"
     ]
    }
   ],
   "source": [
    "write_stories_to_txt(df, \"context.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader #load the document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #for creating chunks from the loaded document\n",
    "from langchain_openai import OpenAIEmbeddings #for converting chunks into embeddings\n",
    "from langchain_chroma import Chroma #database for stroring the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joanneliu/Desktop/AI4DM/H3M3/FlaskApp_Template/chroma_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = os.getcwd()\n",
    "db_dir = os.path.join(dir,\"chroma_db\")\n",
    "print(db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text content from the .txt file and load it as langchain document\n",
    "loader = TextLoader('contextStories.txt')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('context.txt')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document chunk info:\n",
      "\n",
      "Number of document chunks: 267\n",
      "Sample chunk: \n",
      "A hemisphere is half of a sphere, but not exactly a half sphere. A sphere is a three-dimensional shape that is perfectly round and symmetrical all the way around. If you cut a sphere in half through its center, you would get a hemisphere.\n",
      "\n",
      "Now, a half sphere is half of a sphere, but it's more like a soft drink cup or a bowl. It's not symmetrical all the way around. If you were to cut a half sphere in half again, you wouldn't get two identical hemispheres, because the original half sphere wasn't symmetrical to begin with.\n",
      "\n",
      "In other words, a hemisphere is always exactly half of a sphere, but a half sphere isn't necessarily half of a sphere. Does that make sense?\n",
      "\n",
      "Imagine a beach ball. If you cut it in half through its center, you'll get two hemispheres (they'll be identical). But if you cut it in half through the middle, but not through the center, you'll get two non-identical half spheres.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the document into chunks using text splitters \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(document)\n",
    "\n",
    "print(\"Document chunk info:\\n\")\n",
    "print(f\"Number of document chunks: {len(chunks)}\")\n",
    "print(f\"Sample chunk: \\n{chunks[3].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embeddings using openAI embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1663730d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the embeddings and chunks into Chroma DB\n",
    "Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the DB for retrieval\n",
    "embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorDB = Chroma(persist_directory=db_dir,embedding_function=embeddings_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up Retriver\n",
    "retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRetriever(dir):\n",
    "    \"\"\"\n",
    "    dir is the directory of the vector DB\n",
    "    \"\"\"\n",
    "    embeddings_used = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorDB = Chroma(persist_directory=dir,embedding_function=embeddings_used)\n",
    "    retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storyRephrase_langChain_RAG(msg,theme,retrieverDir):\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "            timeout=None,\n",
    "            max_retries=2\n",
    "        )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a high school reading tutor to let students undersand the story {scenario_lang} better based around the theme of {theme}\" \n",
    "        \"Use the following pieces of retrieved context to rephrase the story {scenario_lang} to words about {theme}. Use the word {theme}\"\n",
    "        \"Use simple sentences and simple words for students to understand better\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{scenario_lang}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    retriever = getRetriever(retrieverDir)\n",
    "\n",
    "    out_message = rag_chain.invoke({\n",
    "            \"theme\" : theme,\n",
    "            \"context\":retriever,\n",
    "            \"scenario_lang\" : msg,\n",
    "        })\n",
    "    \n",
    "    return out_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball is a sport where two teams try to score points by throwing a ball into a hoop. It's a game that brings people together, regardless of their skin color. In some places, like the south, people believe that discrimination based on skin color is not common. Instead, people might face challenges because of their culture, how much money they have, or who they are friends with. These things are more important than the color of your skin. So, when you play basketball, remember that everyone is equal on the court, and what matters most is how you play and treat others.\n"
     ]
    }
   ],
   "source": [
    "question = \"I understand the view I suppose, but it seems to me that blatant discrimination on skin color is very rare, at least in my parts of the south. The greater stigmas are cultural and economic, and will be based on your own belief, class, and your childs name and friends. None of these will change because of the skin color of your partner.\" #example output from huggingface model\n",
    "newQ = storyRephrase_langChain_RAG(\"basketball\", question, db_dir)\n",
    "print(newQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
